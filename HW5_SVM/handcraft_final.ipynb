{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OC_P8bFMzILD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.optim import SGD\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "seed = 3047\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FucrkOKI3m_c",
        "outputId": "50709465-e73a-493c-d865-d101812115ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o0m3jyfmetUOJ146TqHuEGUWwQyC7JXV\n",
            "To: /content/train.csv\n",
            "100% 6.54M/6.54M [00:00<00:00, 93.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1B5OC3R0yM8F7yjoYOKu3t08QZalcr7DC\n",
            "To: /content/val.csv\n",
            "100% 665k/665k [00:00<00:00, 87.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2\n",
            "To: /content/X_test\n",
            "100% 3.57M/3.57M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1o0m3jyfmetUOJ146TqHuEGUWwQyC7JXV\n",
        "!gdown 1B5OC3R0yM8F7yjoYOKu3t08QZalcr7DC\n",
        "!gdown 1THvOuf_EOn6c_6TLy0Bqs23BP2NraBR2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Iywj8wLF8ppU"
      },
      "outputs": [],
      "source": [
        "class SVM(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SVM, self).__init__() \n",
        "    self.w = nn.Parameter(torch.randn((1, 4)).to(torch.float32))\n",
        "    self.f = nn.Sequential(\n",
        "                  nn.Linear(43, 4),\n",
        "                  nn.Dropout(0.5),\n",
        "                )\n",
        "  def transform(self, x):\n",
        "    x = self.f(x)\n",
        "    return x\n",
        "  def kernel(self, x):\n",
        "    pass\n",
        "  def forward(self, x):\n",
        "    f = torch.matmul(self.transform(x), self.w.T)\n",
        "    #f = torch.matmul(x, self.w.T)\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X2a0522z7IWo"
      },
      "outputs": [],
      "source": [
        "class HingeLoss(nn.Module):\n",
        "  def __init__(self, C):\n",
        "    super(HingeLoss, self).__init__()  \n",
        "    self.C = C\n",
        "  def forward(self, y, f):\n",
        "    # define Hinge loss\n",
        "    hinge_loss = torch.mean(nn.functional.relu(-y*f))\n",
        "    return hinge_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tJvk23dokg9b"
      },
      "outputs": [],
      "source": [
        "# X = pd.read_csv(\"X_train.csv\")  \n",
        "# y = pd.read_csv(\"Y_train.csv\", header = None).values.reshape(-1)\n",
        "# selector = SelectKBest(chi2, k=60)\n",
        "# selector.fit(X, y)\n",
        "# cols = selector.get_support(indices=True)\n",
        "# X_new = X.iloc[:,cols]\n",
        "# KEYS = X_new.keys()\n",
        "# KEYS=KEYS.tolist()\n",
        "# print(KEYS)\n",
        "# dele = [' 1st-4th', ' 5th-6th', ' 7th-8th', ' 9th',' 10th',' 11th',' 12th', ' Bachelors', ' Doctorate', ' HS-grad', ' Masters', ' Preschool', ' Prof-school', ' Some-college' \\\n",
        "#         ,' Divorced', ' Married-civ-spouse', ' Married-spouse-absent', ' Never-married', ' Separated', ' Widowed']\n",
        "# for word in dele: \n",
        "#     KEYS.remove(word)\n",
        "# KEYS.append('edu_degree')\n",
        "# KEYS.append('marriage')\n",
        "KEYS =['age', 'fnlwgt', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', ' Federal-gov', ' Local-gov', ' Private', ' Self-emp-inc', ' Self-emp-not-inc', '?_workclass', ' Adm-clerical', ' Exec-managerial', ' Farming-fishing', ' Handlers-cleaners', ' Machine-op-inspct', ' Other-service', ' Priv-house-serv', ' Prof-specialty', ' Protective-serv', ' Sales', ' Tech-support', ' Transport-moving', '?_occupation', ' Husband', ' Not-in-family', ' Other-relative', ' Own-child', ' Unmarried', ' Wife', ' Amer-Indian-Eskimo', ' Black', ' Other', ' White', ' Columbia', ' Dominican-Republic', ' El-Salvador', ' India', ' Mexico', 'edu_degree', 'marriage']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iBTrbIzE_AI9"
      },
      "outputs": [],
      "source": [
        "class TrainDataset(Dataset):\n",
        "  def __init__(self, split, mu=None, std=None):\n",
        "    X = pd.read_csv(f\"{split}.csv\")\n",
        "    Y = X['y'].values.reshape(-1) * 2 - 1\n",
        "    X.pop('y')\n",
        "    X = self.education_redesign(X)\n",
        "    X = self.marriage_redesign(X)\n",
        "    X,non,non = self.normalize(X,True,mu,std)\n",
        "    X = self.selection(X,KEYS)\n",
        "    X = pd.DataFrame.from_dict({k: X[k] for k in KEYS})\n",
        "    X = np.concatenate((X, np.ones((X.shape[0], 1))), 1)\n",
        "    self.Y = torch.from_numpy(Y).to(torch.float32)\n",
        "    print('Y',self.Y.size())\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "    print('X',self.X.size())\n",
        "  def normalize(self,X,flag=False, mu_x=None, std_x=None):\n",
        "    #pass\n",
        "    if flag==False:\n",
        "        mu_x= []\n",
        "        std_x =[]\n",
        "    else:\n",
        "        count=0\n",
        "    for key in ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss',\"edu_degree\"]:\n",
        "        X[key]=(X[key]-X[key].mean())/X[key].std()\n",
        "#         if  flag==False:\n",
        "#             mu_x.append(X[key].mean())\n",
        "#             std_x.append(X[key].std())\n",
        "#             X[key]=(X[key]-X[key].mean())/X[key].std()\n",
        "#         else:\n",
        "#             X[key]=(X[key]-mu_x[count])/std_x[count]           \n",
        "        #count+=1\n",
        "    return X, mu_x, std_x\n",
        "  def education_redesign(self,X):\n",
        "    X[\"edu_degree\"]= X[\" HS-grad\"]*1+ X[\" Bachelors\"]*2+ X[\" Some-college\"]*2+ X[\" Assoc-acdm\"]*3+ X[\" Assoc-voc\"]*3 \\\n",
        "    + X[\" Masters\"]*4+ X[\" Prof-school\"]*5+ X[\" Doctorate\"]*5 \n",
        "    return X\n",
        "  def marriage_redesign(self,X):\n",
        "      X[\"marriage\"]= X[' Married-civ-spouse']*1+ X[' Married-spouse-absent']*1+ X[' Married-AF-spouse']*1+ X[\" Divorced\"]*0+ X[\" Separated\"]*0 \\\n",
        "      + X[\" Widowed\"]*0+ X[\" Never-married\"]*-1 \n",
        "      return X\n",
        "  def selection(self,X,keys):\n",
        "    selX = pd.DataFrame.from_dict({k: X[k] for k in keys})\n",
        "    return selX\n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.Y[idx]\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self, mu= None, std=None):\n",
        "    X = pd.read_csv(\"X_test\")\n",
        "    X = self.education_redesign(X)\n",
        "    X = self.marriage_redesign(X)\n",
        "    X = self.normalize(X)\n",
        "    X = self.selection(X,KEYS)\n",
        "    X = pd.DataFrame.from_dict({k: X[k] for k in KEYS})\n",
        "    X = np.concatenate((X, np.ones((X.shape[0], 1))), 1)\n",
        "    self.X = torch.from_numpy(X).to(torch.float32)\n",
        "\n",
        "  def normalize(self,X,flag=False):\n",
        "    #pass\n",
        "    if flag==False:\n",
        "        mu_x= []\n",
        "        std_x =[]\n",
        "    else:\n",
        "        count=0\n",
        "    for key in ['age', 'fnlwgt', 'hours_per_week', 'capital_gain', 'capital_loss',\"edu_degree\"]:\n",
        "        X[key]=(X[key]-X[key].mean())/X[key].std()\n",
        "#         if  flag==False:\n",
        "#             mu_x.append(X[key].mean())\n",
        "#             std_x.append(X[key].std())\n",
        "#             X[key]=(X[key]-X[key].mean())/X[key].std()\n",
        "#         else:\n",
        "#             X[key]=(X[key]-mu_x[count])/std_x[count   \n",
        "        #count+=1\n",
        "    return X\n",
        "  def education_redesign(self,X):\n",
        "    X[\"edu_degree\"]= X[\" HS-grad\"]*1+ X[\" Bachelors\"]*2+ X[\" Some-college\"]*2+ X[\" Assoc-acdm\"]*3+ X[\" Assoc-voc\"]*3 \\\n",
        "    + X[\" Masters\"]*4+ X[\" Prof-school\"]*5+ X[\" Doctorate\"]*5 \n",
        "    return X\n",
        "  def marriage_redesign(self,X):\n",
        "      X[\"marriage\"]= X[' Married-civ-spouse']*1+ X[' Married-spouse-absent']*1+ X[' Married-AF-spouse']*1+ X[\" Divorced\"]*0+ X[\" Separated\"]*0 \\\n",
        "      + X[\" Widowed\"]*0+ X[\" Never-married\"]*-1 \n",
        "      return X\n",
        "  def selection(self,X,keys):\n",
        "    selX = pd.DataFrame.from_dict({k: X[k] for k in keys})\n",
        "    return selX\n",
        "  def __len__(self):\n",
        "    return self.X.size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "m5PZP044Pxuu"
      },
      "outputs": [],
      "source": [
        "def train(train_data, val_data, model, optim, C, device='cuda:0'):\n",
        "    epoch = 20\n",
        "    objective = HingeLoss(C)\n",
        "    objective = objective.to(device)\n",
        "    steps = 0\n",
        "    best = 0\n",
        "    preds1 = None\n",
        "\n",
        "    for e in range(epoch):\n",
        "      # TODO : try to implement gradient descent\n",
        "      #acct = []\n",
        "      for tr in train_data:\n",
        "        steps += 1\n",
        "        x_train, y_train = tr\n",
        "        x_train, y_train = x_train.to(device), y_train.to(device)\n",
        "        pred = model(x_train).squeeze(1)\n",
        "        loss = objective(pred, y_train) + 1 / 2 * torch.sum(model.w[:-1] ** 2)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        \n",
        "        if steps % 100 == 0:\n",
        "          model.eval()\n",
        "          with torch.no_grad():\n",
        "            acc = []\n",
        "            preds = []\n",
        "            for val in val_data:\n",
        "              x_val, y_val = val\n",
        "              x_val , y_val = x_val.to(device), y_val.to(device)\n",
        "              pred = model(x_val).squeeze(1)\n",
        "              pred = (pred > 0) * 2 - 1\n",
        "              result = (y_val.item() == pred)\n",
        "              #preds += [pred.item()]\n",
        "              acc += [(float(result.sum()) / result.size(0))]\n",
        "            #if preds1 != preds:\n",
        "            #  print('change')\n",
        "            #preds1 = preds \n",
        "            #print(preds)\n",
        "            acc = max(sum(acc) / len(acc),1-sum(acc) / len(acc))\n",
        "            #Acct = sum(acct) / len(acct)\n",
        "            print(f'Steps {steps}| Train Loss = {loss.item()}| Val acc = {acc}')\n",
        "            if acc > best:\n",
        "              torch.save(model.state_dict(), 'best_n.ckpt')\n",
        "              best = acc        \n",
        "          model.train()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ucnbZEiVPia3"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "batch = 32\n",
        "C = 1#1\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA-cuRm7pOXo",
        "outputId": "cb5a4051-ca5c-405b-8db6-c8158e4b5595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-0221dae65e17>:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[\"edu_degree\"]= X[\" HS-grad\"]*1+ X[\" Bachelors\"]*2+ X[\" Some-college\"]*2+ X[\" Assoc-acdm\"]*3+ X[\" Assoc-voc\"]*3 \\\n",
            "<ipython-input-30-0221dae65e17>:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[\"marriage\"]= X[' Married-civ-spouse']*1+ X[' Married-spouse-absent']*1+ X[' Married-AF-spouse']*1+ X[\" Divorced\"]*0+ X[\" Separated\"]*0 \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y torch.Size([29561])\n",
            "X torch.Size([29561, 43])\n",
            "Y torch.Size([3000])\n",
            "X torch.Size([3000, 43])\n"
          ]
        }
      ],
      "source": [
        "trainset = TrainDataset('train')\n",
        "devset = TrainDataset('val')\n",
        "testset = TestDataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF1QyZXG4eI7",
        "outputId": "ff991a61-c868-4333-dbcf-05d25be6478c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-0221dae65e17>:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[\"edu_degree\"]= X[\" HS-grad\"]*1+ X[\" Bachelors\"]*2+ X[\" Some-college\"]*2+ X[\" Assoc-acdm\"]*3+ X[\" Assoc-voc\"]*3 \\\n",
            "<ipython-input-30-0221dae65e17>:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  X[\"marriage\"]= X[' Married-civ-spouse']*1+ X[' Married-spouse-absent']*1+ X[' Married-AF-spouse']*1+ X[\" Divorced\"]*0+ X[\" Separated\"]*0 \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y torch.Size([29561])\n",
            "X torch.Size([29561, 43])\n",
            "Y torch.Size([3000])\n",
            "X torch.Size([3000, 43])\n",
            "Steps 100| Train Loss = 0.11479207873344421| Val acc = 0.6196666666666667\n",
            "Steps 200| Train Loss = 0.0829077735543251| Val acc = 0.679\n",
            "Steps 300| Train Loss = 0.054673463106155396| Val acc = 0.7133333333333334\n",
            "Steps 400| Train Loss = 0.10333210229873657| Val acc = 0.7376666666666667\n",
            "Steps 500| Train Loss = 0.034306082874536514| Val acc = 0.749\n",
            "Steps 600| Train Loss = 0.09487834572792053| Val acc = 0.7613333333333333\n",
            "Steps 700| Train Loss = 0.07967253774404526| Val acc = 0.7643333333333333\n",
            "Steps 800| Train Loss = 0.10057765245437622| Val acc = 0.772\n",
            "Steps 900| Train Loss = 0.0489596351981163| Val acc = 0.7773333333333333\n",
            "Steps 1000| Train Loss = 0.06218215450644493| Val acc = 0.778\n",
            "Steps 1100| Train Loss = 0.030485931783914566| Val acc = 0.7813333333333333\n",
            "Steps 1200| Train Loss = 0.03902481123805046| Val acc = 0.784\n",
            "Steps 1300| Train Loss = 0.08035322278738022| Val acc = 0.7863333333333333\n",
            "Steps 1400| Train Loss = 0.09289155155420303| Val acc = 0.788\n",
            "Steps 1500| Train Loss = 0.016619741916656494| Val acc = 0.787\n",
            "Steps 1600| Train Loss = 0.03662168234586716| Val acc = 0.7883333333333333\n",
            "Steps 1700| Train Loss = 0.03142225742340088| Val acc = 0.7936666666666666\n",
            "Steps 1800| Train Loss = 0.05678671598434448| Val acc = 0.793\n",
            "Steps 1900| Train Loss = 0.02601492777466774| Val acc = 0.7956666666666666\n",
            "Steps 2000| Train Loss = 0.030141659080982208| Val acc = 0.797\n",
            "Steps 2100| Train Loss = 0.020986411720514297| Val acc = 0.795\n",
            "Steps 2200| Train Loss = 0.0635981634259224| Val acc = 0.796\n",
            "Steps 2300| Train Loss = 0.07697179913520813| Val acc = 0.7956666666666666\n",
            "Steps 2400| Train Loss = 0.08422231674194336| Val acc = 0.796\n",
            "Steps 2500| Train Loss = 0.057398874312639236| Val acc = 0.7993333333333333\n",
            "Steps 2600| Train Loss = 0.0562937930226326| Val acc = 0.7986666666666666\n",
            "Steps 2700| Train Loss = 0.04008365422487259| Val acc = 0.7976666666666666\n",
            "Steps 2800| Train Loss = 0.031208032742142677| Val acc = 0.8026666666666666\n",
            "Steps 2900| Train Loss = 0.02888859063386917| Val acc = 0.8053333333333333\n",
            "Steps 3000| Train Loss = 0.039139918982982635| Val acc = 0.8033333333333333\n",
            "Steps 3100| Train Loss = 0.036391835659742355| Val acc = 0.8023333333333333\n",
            "Steps 3200| Train Loss = 0.022026576101779938| Val acc = 0.8063333333333333\n",
            "Steps 3300| Train Loss = 0.02334159053862095| Val acc = 0.806\n",
            "Steps 3400| Train Loss = 0.022449437528848648| Val acc = 0.806\n",
            "Steps 3500| Train Loss = 0.027976490557193756| Val acc = 0.8083333333333333\n",
            "Steps 3600| Train Loss = 0.023299604654312134| Val acc = 0.8096666666666666\n",
            "Steps 3700| Train Loss = 0.06029257923364639| Val acc = 0.8106666666666666\n",
            "Steps 3800| Train Loss = 0.01564350537955761| Val acc = 0.8083333333333333\n",
            "Steps 3900| Train Loss = 0.030649760738015175| Val acc = 0.808\n",
            "Steps 4000| Train Loss = 0.019788023084402084| Val acc = 0.8126666666666666\n",
            "Steps 4100| Train Loss = 0.026065615937113762| Val acc = 0.8123333333333334\n",
            "Steps 4200| Train Loss = 0.03874123841524124| Val acc = 0.8113333333333334\n",
            "Steps 4300| Train Loss = 0.05033791437745094| Val acc = 0.81\n",
            "Steps 4400| Train Loss = 0.019674552604556084| Val acc = 0.8103333333333333\n",
            "Steps 4500| Train Loss = 0.013502516783773899| Val acc = 0.812\n",
            "Steps 4600| Train Loss = 0.01180629339069128| Val acc = 0.8123333333333334\n",
            "Steps 4700| Train Loss = 0.04385063052177429| Val acc = 0.8123333333333334\n",
            "Steps 4800| Train Loss = 0.032915472984313965| Val acc = 0.8103333333333333\n",
            "Steps 4900| Train Loss = 0.02213156968355179| Val acc = 0.8126666666666666\n",
            "Steps 5000| Train Loss = 0.00961309764534235| Val acc = 0.8116666666666666\n",
            "Steps 5100| Train Loss = 0.031830839812755585| Val acc = 0.8143333333333334\n",
            "Steps 5200| Train Loss = 0.0171622633934021| Val acc = 0.8153333333333334\n",
            "Steps 5300| Train Loss = 0.009677127003669739| Val acc = 0.8153333333333334\n",
            "Steps 5400| Train Loss = 0.0467500276863575| Val acc = 0.814\n",
            "Steps 5500| Train Loss = 0.03201443329453468| Val acc = 0.8153333333333334\n",
            "Steps 5600| Train Loss = 0.04627659544348717| Val acc = 0.8163333333333334\n",
            "Steps 5700| Train Loss = 0.015882987529039383| Val acc = 0.816\n",
            "Steps 5800| Train Loss = 0.015070726163685322| Val acc = 0.8143333333333334\n",
            "Steps 5900| Train Loss = 0.004467350896447897| Val acc = 0.8133333333333334\n",
            "Steps 6000| Train Loss = 0.035498324781656265| Val acc = 0.816\n",
            "Steps 6100| Train Loss = 0.02677212655544281| Val acc = 0.816\n",
            "Steps 6200| Train Loss = 0.042661089450120926| Val acc = 0.814\n",
            "Steps 6300| Train Loss = 0.018083874136209488| Val acc = 0.8153333333333334\n",
            "Steps 6400| Train Loss = 0.02774389088153839| Val acc = 0.8143333333333334\n",
            "Steps 6500| Train Loss = 0.009169830940663815| Val acc = 0.814\n",
            "Steps 6600| Train Loss = 0.008700075559318066| Val acc = 0.8163333333333334\n",
            "Steps 6700| Train Loss = 0.01580539345741272| Val acc = 0.8173333333333334\n",
            "Steps 6800| Train Loss = 0.025816692039370537| Val acc = 0.8173333333333334\n",
            "Steps 6900| Train Loss = 0.00043673464097082615| Val acc = 0.8153333333333334\n",
            "Steps 7000| Train Loss = 0.027935868129134178| Val acc = 0.817\n",
            "Steps 7100| Train Loss = 0.008876618929207325| Val acc = 0.817\n",
            "Steps 7200| Train Loss = 0.006961603183299303| Val acc = 0.816\n",
            "Steps 7300| Train Loss = 0.015895701944828033| Val acc = 0.817\n",
            "Steps 7400| Train Loss = 0.0038912242744117975| Val acc = 0.8196666666666667\n",
            "Steps 7500| Train Loss = 0.0019383078906685114| Val acc = 0.82\n",
            "Steps 7600| Train Loss = 0.03428153693675995| Val acc = 0.8196666666666667\n",
            "Steps 7700| Train Loss = 0.026396816596388817| Val acc = 0.819\n",
            "Steps 7800| Train Loss = 0.0028254820499569178| Val acc = 0.8173333333333334\n",
            "Steps 7900| Train Loss = 0.024333572015166283| Val acc = 0.819\n",
            "Steps 8000| Train Loss = 0.010964740067720413| Val acc = 0.817\n",
            "Steps 8100| Train Loss = 0.0034669083543121815| Val acc = 0.8173333333333334\n",
            "Steps 8200| Train Loss = 0.0039916313253343105| Val acc = 0.8196666666666667\n",
            "Steps 8300| Train Loss = 0.010547042824327946| Val acc = 0.8166666666666667\n",
            "Steps 8400| Train Loss = 0.006250140722841024| Val acc = 0.8173333333333334\n",
            "Steps 8500| Train Loss = 0.010049810633063316| Val acc = 0.82\n",
            "Steps 8600| Train Loss = 0.011526561342179775| Val acc = 0.819\n",
            "Steps 8700| Train Loss = 0.0351104661822319| Val acc = 0.8163333333333334\n",
            "Steps 8800| Train Loss = 0.005582360550761223| Val acc = 0.819\n",
            "Steps 8900| Train Loss = 0.0059130070731043816| Val acc = 0.8156666666666667\n",
            "Steps 9000| Train Loss = 0.01516539417207241| Val acc = 0.817\n",
            "Steps 9100| Train Loss = 0.004376981407403946| Val acc = 0.816\n",
            "Steps 9200| Train Loss = 0.001897064154036343| Val acc = 0.8136666666666666\n",
            "Steps 9300| Train Loss = 0.006668849382549524| Val acc = 0.8206666666666667\n",
            "Steps 9400| Train Loss = 0.003513348987326026| Val acc = 0.8206666666666667\n",
            "Steps 9500| Train Loss = 0.004888299852609634| Val acc = 0.8203333333333334\n",
            "Steps 9600| Train Loss = 0.017496643587946892| Val acc = 0.8193333333333334\n",
            "Steps 9700| Train Loss = 0.011346898972988129| Val acc = 0.8203333333333334\n",
            "Steps 9800| Train Loss = 0.0026633006054908037| Val acc = 0.8163333333333334\n",
            "Steps 9900| Train Loss = 0.005741641391068697| Val acc = 0.8193333333333334\n",
            "Steps 10000| Train Loss = 0.006726624444127083| Val acc = 0.8173333333333334\n",
            "Steps 10100| Train Loss = 0.013478160835802555| Val acc = 0.8176666666666667\n",
            "Steps 10200| Train Loss = 0.005042768083512783| Val acc = 0.8176666666666667\n",
            "Steps 10300| Train Loss = 0.015246717259287834| Val acc = 0.8213333333333334\n",
            "Steps 10400| Train Loss = 0.016219621524214745| Val acc = 0.8193333333333334\n",
            "Steps 10500| Train Loss = 0.014171693474054337| Val acc = 0.8213333333333334\n",
            "Steps 10600| Train Loss = 0.008008782751858234| Val acc = 0.818\n",
            "Steps 10700| Train Loss = 0.004917376209050417| Val acc = 0.817\n",
            "Steps 10800| Train Loss = 0.0009581887279637158| Val acc = 0.819\n",
            "Steps 10900| Train Loss = 0.03433488681912422| Val acc = 0.819\n",
            "Steps 11000| Train Loss = 0.010358631610870361| Val acc = 0.8183333333333334\n",
            "Steps 11100| Train Loss = 0.0036015671212226152| Val acc = 0.8196666666666667\n",
            "Steps 11200| Train Loss = 0.0064155724830925465| Val acc = 0.8173333333333334\n",
            "Steps 11300| Train Loss = 0.010001054033637047| Val acc = 0.8156666666666667\n",
            "Steps 11400| Train Loss = 0.006402126979082823| Val acc = 0.815\n",
            "Steps 11500| Train Loss = 0.013906565494835377| Val acc = 0.8186666666666667\n",
            "Steps 11600| Train Loss = 0.02359643764793873| Val acc = 0.8196666666666667\n",
            "Steps 11700| Train Loss = 0.013590652495622635| Val acc = 0.82\n",
            "Steps 11800| Train Loss = 0.016642317175865173| Val acc = 0.8233333333333334\n",
            "Steps 11900| Train Loss = 0.015343215316534042| Val acc = 0.822\n",
            "Steps 12000| Train Loss = 0.006683209910988808| Val acc = 0.8196666666666667\n",
            "Steps 12100| Train Loss = 0.00627190200611949| Val acc = 0.8236666666666667\n",
            "Steps 12200| Train Loss = 0.007796378340572119| Val acc = 0.8213333333333334\n",
            "Steps 12300| Train Loss = 0.01142141968011856| Val acc = 0.8206666666666667\n",
            "Steps 12400| Train Loss = 0.01878666877746582| Val acc = 0.8246666666666667\n",
            "Steps 12500| Train Loss = 0.004623211920261383| Val acc = 0.8193333333333334\n",
            "Steps 12600| Train Loss = 0.01728011667728424| Val acc = 0.821\n",
            "Steps 12700| Train Loss = 0.006559737026691437| Val acc = 0.821\n",
            "Steps 12800| Train Loss = 0.007652774453163147| Val acc = 0.826\n",
            "Steps 12900| Train Loss = 0.005182635970413685| Val acc = 0.8223333333333334\n",
            "Steps 13000| Train Loss = 0.005052890628576279| Val acc = 0.822\n",
            "Steps 13100| Train Loss = 0.014709603041410446| Val acc = 0.825\n",
            "Steps 13200| Train Loss = 0.010538085363805294| Val acc = 0.8203333333333334\n",
            "Steps 13300| Train Loss = 0.0058946325443685055| Val acc = 0.823\n",
            "Steps 13400| Train Loss = 0.0004993687616661191| Val acc = 0.822\n",
            "Steps 13500| Train Loss = 0.008050166070461273| Val acc = 0.824\n",
            "Steps 13600| Train Loss = 0.003358205547556281| Val acc = 0.8226666666666667\n",
            "Steps 13700| Train Loss = 0.002274679020047188| Val acc = 0.825\n",
            "Steps 13800| Train Loss = 0.003479347098618746| Val acc = 0.8223333333333334\n",
            "Steps 13900| Train Loss = 0.0052396743558347225| Val acc = 0.8216666666666667\n",
            "Steps 14000| Train Loss = 0.011054495349526405| Val acc = 0.8223333333333334\n",
            "Steps 14100| Train Loss = 0.005219846498221159| Val acc = 0.823\n",
            "Steps 14200| Train Loss = 0.005330812186002731| Val acc = 0.824\n",
            "Steps 14300| Train Loss = 0.012311057187616825| Val acc = 0.8233333333333334\n",
            "Steps 14400| Train Loss = 0.0029530543833971024| Val acc = 0.8206666666666667\n",
            "Steps 14500| Train Loss = 0.003729347139596939| Val acc = 0.8213333333333334\n",
            "Steps 14600| Train Loss = 0.005462460685521364| Val acc = 0.8206666666666667\n",
            "Steps 14700| Train Loss = 0.002942811232060194| Val acc = 0.824\n",
            "Steps 14800| Train Loss = 0.0033464799635112286| Val acc = 0.825\n",
            "Steps 14900| Train Loss = 0.001214291201904416| Val acc = 0.8246666666666667\n",
            "Steps 15000| Train Loss = 0.004301377572119236| Val acc = 0.817\n",
            "Steps 15100| Train Loss = 0.002853487618267536| Val acc = 0.8216666666666667\n",
            "Steps 15200| Train Loss = 0.0053128087893128395| Val acc = 0.8243333333333334\n",
            "Steps 15300| Train Loss = 0.006709711626172066| Val acc = 0.8246666666666667\n",
            "Steps 15400| Train Loss = 0.010370460338890553| Val acc = 0.8243333333333334\n",
            "Steps 15500| Train Loss = 0.0024502670858055353| Val acc = 0.8233333333333334\n",
            "Steps 15600| Train Loss = 0.00956799928098917| Val acc = 0.823\n",
            "Steps 15700| Train Loss = 0.0014778291806578636| Val acc = 0.821\n",
            "Steps 15800| Train Loss = 0.004539976827800274| Val acc = 0.8196666666666667\n",
            "Steps 15900| Train Loss = 0.0007161066168919206| Val acc = 0.82\n",
            "Steps 16000| Train Loss = 0.0034601592924445868| Val acc = 0.823\n",
            "Steps 16100| Train Loss = 0.00233859452418983| Val acc = 0.8226666666666667\n",
            "Steps 16200| Train Loss = 0.002209659665822983| Val acc = 0.8173333333333334\n",
            "Steps 16300| Train Loss = 0.009487824514508247| Val acc = 0.82\n",
            "Steps 16400| Train Loss = 0.003045781049877405| Val acc = 0.8223333333333334\n",
            "Steps 16500| Train Loss = 0.0020791972056031227| Val acc = 0.822\n",
            "Steps 16600| Train Loss = 0.008313464932143688| Val acc = 0.8256666666666667\n",
            "Steps 16700| Train Loss = 0.001478581689298153| Val acc = 0.822\n",
            "Steps 16800| Train Loss = 0.006866489537060261| Val acc = 0.8183333333333334\n",
            "Steps 16900| Train Loss = 0.0025434112176299095| Val acc = 0.824\n",
            "Steps 17000| Train Loss = 0.003554311580955982| Val acc = 0.8246666666666667\n",
            "Steps 17100| Train Loss = 0.009748958051204681| Val acc = 0.8113333333333334\n",
            "Steps 17200| Train Loss = 0.001638985238969326| Val acc = 0.824\n",
            "Steps 17300| Train Loss = 0.002235786523669958| Val acc = 0.82\n",
            "Steps 17400| Train Loss = 0.004879981279373169| Val acc = 0.8196666666666667\n",
            "Steps 17500| Train Loss = 0.006712454371154308| Val acc = 0.8176666666666667\n",
            "Steps 17600| Train Loss = 0.01028621755540371| Val acc = 0.8186666666666667\n",
            "Steps 17700| Train Loss = 0.0034918475430458784| Val acc = 0.8213333333333334\n",
            "Steps 17800| Train Loss = 0.0077501810155808926| Val acc = 0.8206666666666667\n",
            "Steps 17900| Train Loss = 0.004470278508961201| Val acc = 0.8226666666666667\n",
            "Steps 18000| Train Loss = 0.005175448954105377| Val acc = 0.823\n",
            "Steps 18100| Train Loss = 0.003587364451959729| Val acc = 0.8196666666666667\n",
            "Steps 18200| Train Loss = 0.0018191153649240732| Val acc = 0.816\n",
            "Steps 18300| Train Loss = 0.01202615350484848| Val acc = 0.8203333333333334\n",
            "Steps 18400| Train Loss = 0.008763233199715614| Val acc = 0.8153333333333334\n"
          ]
        }
      ],
      "source": [
        "trainset = TrainDataset('train')\n",
        "devset = TrainDataset('val')\n",
        "testset = TestDataset()\n",
        "\n",
        "train_dataloader = DataLoader(trainset, batch, True, drop_last=False)\n",
        "val_dataloader = DataLoader(devset, 1, False)\n",
        "test_dataloader = DataLoader(testset, 1, False)\n",
        "\n",
        "model = SVM().to(device) \n",
        "#model.load_state_dict(torch.load('best_n.ckpt'))\n",
        "optim = SGD(model.parameters(), lr)\n",
        "model = train(train_dataloader, val_dataloader, model, optim, C, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "42J0DE2DQQ8u"
      },
      "outputs": [],
      "source": [
        "best_model = model\n",
        "best_model.load_state_dict(torch.load('best_n.ckpt'))\n",
        "best_model = best_model.eval()\n",
        "# TODO: predict x_test\n",
        "y_test = []\n",
        "for x in test_dataloader:\n",
        "  x = x.to(device)\n",
        "  y = best_model(x)\n",
        "  y_test.append(((y > 0) * 1).item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sYJnjxOiQKqB"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('predict_4.csv', 'w', newline='') as csvf:\n",
        "    # 建立 CSV 檔寫入器\n",
        "    writer = csv.writer(csvf)\n",
        "    writer.writerow(['id','label'])\n",
        "    for i in range(len(y_test)):\n",
        "      writer.writerow( [i + 1, int(y_test[i])] )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}