{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxuVdRvdBSFi"
   },
   "source": [
    "# HW4 RNN\n",
    "Task: Sentiment classification on Twitter comments.\n",
    "\n",
    "Goal of this homework:\n",
    "*   Get familiar with the recurrent neural network.\n",
    "*   Learn how to deal with text data\n",
    "\n",
    "TA: Chih-Kai, Yang (b08202033@ntu.edu.tw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD__8ohVBhjx"
   },
   "source": [
    "Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ybs7iymbWbER"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FrO0GquBkN8"
   },
   "source": [
    "Download the dataset and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRjym0iYOoPN",
    "outputId": "26788b47-f4b0-4af2-ae78-f89e569b1eec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  category=FutureWarning,\n",
      "Access denied with the following error:\n",
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gdown --id \"1cwPgbbAMNPZ9nCoyOW2WuavimYymCKKy\" --output DATASET.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9vdBfpImp-r",
    "outputId": "45f95c01-7dbc-42e0-8a9b-874f30fbd2f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- --------------------\n",
      "alabaster                          0.7.12\n",
      "anaconda-client                    1.9.0\n",
      "anaconda-navigator                 2.1.1\n",
      "anaconda-project                   0.10.1\n",
      "anyio                              2.2.0\n",
      "appdirs                            1.4.4\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "arrow                              0.13.1\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.6.6\n",
      "astropy                            4.3.1\n",
      "async-generator                    1.10\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              21.2.0\n",
      "autopep8                           1.5.7\n",
      "Babel                              2.9.1\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.10.0\n",
      "binaryornot                        0.4.4\n",
      "bitarray                           2.3.0\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             4.0.0\n",
      "bokeh                              2.4.1\n",
      "boto                               2.49.0\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "cached-property                    1.5.2\n",
      "certifi                            2021.10.8\n",
      "cffi                               1.14.6\n",
      "chardet                            4.0.0\n",
      "charset-normalizer                 2.0.4\n",
      "click                              8.0.3\n",
      "cloudpickle                        2.0.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.4\n",
      "comtypes                           1.1.10\n",
      "conda                              4.12.0\n",
      "conda-build                        3.21.6\n",
      "conda-content-trust                0+unknown\n",
      "conda-pack                         0.6.0\n",
      "conda-package-handling             1.7.3\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "contextlib2                        0.6.0.post1\n",
      "cookiecutter                       1.7.2\n",
      "cryptography                       3.4.8\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.28\n",
      "cytoolz                            0.11.0\n",
      "daal4py                            2021.3.0\n",
      "dask                               2021.10.0\n",
      "debugpy                            1.4.1\n",
      "decorator                          5.1.0\n",
      "defusedxml                         0.7.1\n",
      "diff-match-patch                   20200713\n",
      "distributed                        2021.10.0\n",
      "docutils                           0.17.1\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.1.0\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.3.1\n",
      "flake8                             3.9.2\n",
      "Flask                              1.1.2\n",
      "fonttools                          4.25.0\n",
      "fsspec                             2021.10.1\n",
      "future                             0.18.2\n",
      "gensim                             4.2.0\n",
      "gevent                             21.8.0\n",
      "glob2                              0.7\n",
      "greenlet                           1.1.1\n",
      "h5py                               3.2.1\n",
      "HeapDict                           1.0.1\n",
      "html5lib                           1.1\n",
      "idna                               3.2\n",
      "imagecodecs                        2021.8.26\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "importlib-metadata                 4.8.1\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          6.4.1\n",
      "ipython                            7.29.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.6.5\n",
      "isort                              5.9.3\n",
      "itsdangerous                       2.0.1\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.18.0\n",
      "Jinja2                             2.11.3\n",
      "jinja2-time                        0.2.0\n",
      "joblib                             1.1.0\n",
      "json5                              0.9.6\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.12\n",
      "jupyter-console                    6.4.0\n",
      "jupyter-core                       4.8.1\n",
      "jupyter-server                     1.4.1\n",
      "jupyterlab                         3.2.1\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.8.2\n",
      "jupyterlab-widgets                 1.0.0\n",
      "keyring                            23.1.0\n",
      "kiwisolver                         1.3.1\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "llvmlite                           0.37.0\n",
      "locket                             0.2.1\n",
      "lxml                               4.6.3\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.4.3\n",
      "matplotlib-inline                  0.1.2\n",
      "mccabe                             0.6.1\n",
      "menuinst                           1.4.18\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.1\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.10.0\n",
      "mpmath                             1.2.1\n",
      "msgpack                            1.0.2\n",
      "multipledispatch                   0.6.0\n",
      "munkres                            1.1.4\n",
      "mypy-extensions                    0.4.3\n",
      "navigator-updater                  0.2.1\n",
      "nbclassic                          0.2.6\n",
      "nbclient                           0.5.3\n",
      "nbconvert                          6.1.0\n",
      "nbformat                           5.1.3\n",
      "nest-asyncio                       1.5.1\n",
      "networkx                           2.6.3\n",
      "nltk                               3.6.5\n",
      "nose                               1.3.7\n",
      "notebook                           6.4.5\n",
      "numba                              0.54.1\n",
      "numexpr                            2.7.3\n",
      "numpy                              1.20.3\n",
      "numpydoc                           1.1.0\n",
      "olefile                            0.46\n",
      "opencv-python                      4.6.0.66\n",
      "openpyxl                           3.0.9\n",
      "packaging                          21.0\n",
      "pandas                             1.3.4\n",
      "pandocfilters                      1.4.3\n",
      "paramiko                           2.7.2\n",
      "parso                              0.8.2\n",
      "partd                              1.2.0\n",
      "path                               16.0.0\n",
      "pathlib2                           2.3.6\n",
      "pathspec                           0.7.0\n",
      "patsy                              0.5.2\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.4.0\n",
      "pip                                21.2.4\n",
      "pkginfo                            1.7.1\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "poyo                               0.5.0\n",
      "prometheus-client                  0.11.0\n",
      "prompt-toolkit                     3.0.20\n",
      "psutil                             5.8.0\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.10.0\n",
      "pycodestyle                        2.7.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pycurl                             7.44.1\n",
      "pydicom                            2.3.0\n",
      "pydocstyle                         6.1.1\n",
      "pyerfa                             2.0.0\n",
      "pyflakes                           2.3.1\n",
      "Pygments                           2.10.0\n",
      "PyJWT                              2.1.0\n",
      "pylint                             2.9.6\n",
      "pyls-spyder                        0.4.0\n",
      "PyNaCl                             1.4.0\n",
      "pyodbc                             4.0.0-unsupported\n",
      "pyOpenSSL                          21.0.0\n",
      "pyparsing                          3.0.4\n",
      "pyreadline                         2.1\n",
      "pyrsistent                         0.18.0\n",
      "PySocks                            1.7.1\n",
      "pytest                             6.2.4\n",
      "python-dateutil                    2.8.2\n",
      "python-lsp-black                   1.0.0\n",
      "python-lsp-jsonrpc                 1.0.0\n",
      "python-lsp-server                  1.2.4\n",
      "python-slugify                     5.0.2\n",
      "pytz                               2021.3\n",
      "PyWavelets                         1.1.1\n",
      "pywin32                            228\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           0.5.7\n",
      "PyYAML                             6.0\n",
      "pyzmq                              22.2.1\n",
      "QDarkStyle                         3.0.2\n",
      "qstylizer                          0.1.10\n",
      "QtAwesome                          1.0.2\n",
      "qtconsole                          5.1.1\n",
      "QtPy                               1.10.0\n",
      "regex                              2021.8.3\n",
      "requests                           2.26.0\n",
      "rope                               0.19.0\n",
      "Rtree                              0.9.7\n",
      "ruamel-yaml-conda                  0.15.100\n",
      "scikit-image                       0.18.3\n",
      "scikit-learn                       0.24.2\n",
      "scikit-learn-intelex               2021.20210714.120553\n",
      "scipy                              1.7.1\n",
      "seaborn                            0.11.2\n",
      "Send2Trash                         1.8.0\n",
      "setuptools                         58.0.4\n",
      "simplegeneric                      0.8.1\n",
      "SimpleITK                          2.2.0\n",
      "singledispatch                     3.7.0\n",
      "sip                                4.19.13\n",
      "six                                1.16.0\n",
      "smart-open                         6.2.0\n",
      "sniffio                            1.2.0\n",
      "snowballstemmer                    2.1.0\n",
      "sortedcollections                  2.1.0\n",
      "sortedcontainers                   2.4.0\n",
      "soupsieve                          2.2.1\n",
      "Sphinx                             4.2.0\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             2.0.0\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.5\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             5.1.5\n",
      "spyder-kernels                     2.1.3\n",
      "SQLAlchemy                         1.4.22\n",
      "statsmodels                        0.12.2\n",
      "sympy                              1.9\n",
      "tables                             3.6.1\n",
      "TBB                                0.2\n",
      "tblib                              1.7.0\n",
      "terminado                          0.9.4\n",
      "testpath                           0.5.0\n",
      "text-unidecode                     1.3\n",
      "textdistance                       4.2.1\n",
      "threadpoolctl                      2.2.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2021.7.2\n",
      "tinycss                            0.4\n",
      "toml                               0.10.2\n",
      "toolz                              0.11.1\n",
      "torch                              1.13.0\n",
      "torchaudio                         0.13.0\n",
      "torchvision                        0.14.0\n",
      "tornado                            6.1\n",
      "tqdm                               4.62.3\n",
      "traitlets                          5.1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typed-ast                          1.4.3\n",
      "typing-extensions                  3.10.0.2\n",
      "ujson                              4.0.2\n",
      "unicodecsv                         0.14.1\n",
      "Unidecode                          1.2.0\n",
      "urllib3                            1.26.7\n",
      "watchdog                           2.1.3\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "Werkzeug                           2.0.2\n",
      "wheel                              0.37.0\n",
      "whichcraft                         0.6.1\n",
      "widgetsnbextension                 3.5.1\n",
      "win-inet-pton                      1.1.0\n",
      "win-unicode-console                0.5\n",
      "wincertstore                       0.2\n",
      "wrapt                              1.12.1\n",
      "xlrd                               2.0.1\n",
      "XlsxWriter                         3.0.1\n",
      "xlwings                            0.24.9\n",
      "xlwt                               1.3.0\n",
      "xmltodict                          0.12.0\n",
      "yapf                               0.31.0\n",
      "zict                               2.0.0\n",
      "zipp                               3.6.0\n",
      "zope.event                         4.5.0\n",
      "zope.interface                     5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "me7hH5JjO606",
    "outputId": "33abd74f-4f19-44a2-9c39-31090e5fe782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open DATASET.zip, DATASET.zip.zip or DATASET.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip DATASET.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNA6q0rnBwHP"
   },
   "source": [
    "Basic setup of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1VX5NXp4WbEi"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH_NUM = 30\n",
    "MAX_POSITIONS_LEN = 100\n",
    "SEED = 1124 # Set your lucky number as the random seed\n",
    "MODEL_DIR = 'model.pth'\n",
    "lr = 1e-3\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "w2v_config = {'path': 'w2v.model', 'dim': 64}\n",
    "net_config = {'hidden_dim': 32, 'num_layers': 1, 'bidirectional': False, 'fix_embedding': True}\n",
    "header_config = {'dropout': 0.5, 'hidden_dim': 32}\n",
    "assert header_config['hidden_dim'] == net_config['hidden_dim'] or header_config['hidden_dim'] == net_config['hidden_dim'] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxOddxufB2dr"
   },
   "source": [
    "Auxiliary functions and classes definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "v7PZMBJSWbEk"
   },
   "outputs": [],
   "source": [
    "def parsing_text(text):\n",
    "    # TODO: do data processing\n",
    "    removesent = text.split()\n",
    "    newsent=''\n",
    "    for word in removesent:\n",
    "        if 'http' not in word:\n",
    "            newsent+=word+' '\n",
    "    newsent= newsent.replace('.',' .').replace('!',' !').replace('?',' ?').replace(',',' ,').replace('#','')\n",
    "    #text=text.replace(['low fat','LF'], ['Low Fat','Low Fat'])\n",
    "    newsent = newsent.split()\n",
    "    newtxt=''\n",
    "    for i,word in enumerate(newsent):\n",
    "        if '@' not in word:\n",
    "            newtxt+=word+' '\n",
    "        elif i != 0 and '@' in word:\n",
    "            newtxt+='he'+' '\n",
    "    return newtxt\n",
    "\n",
    "def load_train_label(path='HW4_dataset/train.csv'):\n",
    "    tra_lb_pd = pd.read_csv(path)\n",
    "    label = torch.FloatTensor(tra_lb_pd['label'].values)\n",
    "    idx = tra_lb_pd['id'].tolist()\n",
    "    text = [parsing_text(s).split(' ') for s in tra_lb_pd['text'].tolist()]\n",
    "    return idx, text, label\n",
    "\n",
    "def load_train_nolabel(path='HW4_dataset/train_nolabel.csv'):\n",
    "    tra_nlb_pd = pd.read_csv(path)\n",
    "    text = [parsing_text(s).split(' ') for s in tra_nlb_pd['text'].tolist()]\n",
    "    return None, text, None\n",
    "\n",
    "def load_test(path='HW4_dataset/test.csv'):\n",
    "    tst_pd = pd.read_csv(path)\n",
    "    idx = tst_pd['id'].tolist()\n",
    "    text = [parsing_text(s).split(' ') for s in tst_pd['text'].tolist()]\n",
    "    return idx, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "N6JVOfd0WbEo"
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, sentences, w2v_config):\n",
    "        self.sentences = sentences\n",
    "        self.idx2word = []\n",
    "        self.word2idx = {}\n",
    "        self.embedding_matrix = []\n",
    "        self.build_word2vec(sentences, **w2v_config)\n",
    "        \n",
    "    def build_word2vec(self, x, path, dim):\n",
    "        if os.path.isfile(path):\n",
    "            print(\"loading word2vec model ...\")\n",
    "            w2v_model = Word2Vec.load(path)\n",
    "        else:\n",
    "            print(\"training word2vec model ...\")\n",
    "            w2v_model = Word2Vec(x, vector_size=dim, window=5, min_count=2, workers=12, epochs=2, sg=1)\n",
    "            print(\"saving word2vec model ...\")\n",
    "            w2v_model.save(path)\n",
    "            \n",
    "        self.embedding_dim = w2v_model.vector_size\n",
    "        for i, word in enumerate(w2v_model.wv.vocab):\n",
    "            #e.g. self.word2index['he'] = 1 \n",
    "            #e.g. self.index2word[1] = 'he'\n",
    "            #e.g. self.vectors[1] = 'he' vector\n",
    "            \n",
    "            self.word2idx[word] = len(self.word2idx)\n",
    "            self.idx2word.append(word)\n",
    "            self.embedding_matrix.append(w2v_model[word])\n",
    "        \n",
    "        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n",
    "        self.add_embedding('<PAD>')\n",
    "        self.add_embedding('<UNK>')\n",
    "        print(\"total words: {}\".format(len(self.embedding_matrix)))\n",
    "        \n",
    "    def add_embedding(self, word):\n",
    "        # 把 word 加進 embedding，並賦予他一個隨機生成的 representation vector\n",
    "        # word 只會是 \"<PAD>\" 或 \"<UNK>\"\n",
    "        vector = torch.empty(1, self.embedding_dim)\n",
    "        torch.nn.init.uniform_(vector)\n",
    "        self.word2idx[word] = len(self.word2idx)\n",
    "        self.idx2word.append(word)\n",
    "        self.embedding_matrix = torch.cat([self.embedding_matrix, vector], 0)   \n",
    "        \n",
    "    def sentence2idx(self, sentence):\n",
    "        sentence_idx = []\n",
    "        for word in sentence:\n",
    "            if word in self.word2idx.keys():\n",
    "                sentence_idx.append(self.word2idx[word])\n",
    "            else:\n",
    "                sentence_idx.append(self.word2idx[\"<UNK>\"])\n",
    "        return torch.LongTensor(sentence_idx)\n",
    "    \n",
    "class TwitterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, id_list, sentences, labels, preprocessor):\n",
    "        self.id_list = id_list\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is None: return self.id_list[idx], self.preprocessor.sentence2idx(self.sentences[idx])\n",
    "        return self.id_list[idx], self.preprocessor.sentence2idx(self.sentences[idx]), self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        id_list = torch.LongTensor([d[0] for d in data])\n",
    "        lengths = torch.LongTensor([len(d[1]) for d in data])\n",
    "        texts = pad_sequence(\n",
    "            [d[1] for d in data], batch_first=True).contiguous()\n",
    "     \n",
    "        if self.labels == None: \n",
    "            return id_list, lengths, texts\n",
    "        else:\n",
    "          labels = torch.FloatTensor([d[2] for d in data])\n",
    "          return id_list, lengths, texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOOvVdBtKHxM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I1BLWdhMKIWS",
    "outputId": "368eff0e-ab03-4d53-cd4c-d624f238ca85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eh . . . I've been bad . BUT , you following up with me on this is great accountability for me ! Please keep asking ! ! ! \n"
     ]
    }
   ],
   "source": [
    "txt = \"@maddyhubba Eh... I've been bad.  BUT, you following up with me on this is great accountability for me! Please keep asking!!!\"\n",
    "txt = txt.replace('.',' .').replace('!',' !').replace('?',' ?').replace(',',' ,').replace('#','')\n",
    "x = txt.split()\n",
    "newtxt=''\n",
    "for word in x:\n",
    "  if '@' not in word:\n",
    "    newtxt+=word+' '\n",
    "print(newtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "jpK_-m5pWbGZ",
    "outputId": "2703b608-c840-41f1-e9ee-2b90a1f1f4bc"
   },
   "outputs": [],
   "source": [
    "train_idx, train_label_text, label = load_train_label('HW4_dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PwuBppnV-ChI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training word2vec model ...\n",
      "saving word2vec model ...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15672/1069944765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_nolabel_text\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_train_nolabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HW4_dataset/train_nolabel.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_nolabel_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2v_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15672/3138577800.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, w2v_config)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mw2v_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15672/3138577800.py\u001b[0m in \u001b[0;36mbuild_word2vec\u001b[1;34m(self, x, path, dim)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[1;31m#e.g. self.word2index['he'] = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m#e.g. self.index2word[1] = 'he'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    733\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m    736\u001b[0m             \u001b[1;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[1;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "_,train_nolabel_text,_ = load_train_nolabel('HW4_dataset/train_nolabel.csv')\n",
    "preprocessor = Preprocessor(train_nolabel_text, w2v_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAz3ZPtEqLcC"
   },
   "outputs": [],
   "source": [
    "train_idx, valid_idx, train_label_text, valid_label_text, train_label, valid_label = train_test_split(train_idx, train_label_text, label, test_size=0.5)\n",
    "train_dataset, valid_dataset = TwitterDataset(train_idx, train_label_text, train_label, preprocessor), TwitterDataset(valid_idx, valid_label_text, valid_label, preprocessor)\n",
    "\n",
    "test_idx, test_text = load_test('HW4_dataset/test.csv')\n",
    "test_dataset = TwitterDataset(test_idx, test_text, None, preprocessor)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                            batch_size = BATCH_SIZE,\n",
    "                                            shuffle = True,\n",
    "                                            collate_fn = train_dataset.collate_fn,\n",
    "                                            num_workers = 8)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid_dataset,\n",
    "                                            batch_size = BATCH_SIZE,\n",
    "                                            shuffle = False,\n",
    "                                            collate_fn = valid_dataset.collate_fn,\n",
    "                                            num_workers = 8)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                            batch_size = BATCH_SIZE,\n",
    "                                            shuffle = False,\n",
    "                                            collate_fn = test_dataset.collate_fn,\n",
    "                                            num_workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGHVyJwjCBRB"
   },
   "source": [
    "Definition of RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BtL7itbWbGk"
   },
   "outputs": [],
   "source": [
    "class Backbone(torch.nn.Module):\n",
    "    def __init__(self, embedding, hidden_dim, num_layers, bidirectional, fix_embedding=True):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.embedding = embedding\n",
    "        # self.embedding.weight = torch.nn.Parameter(embedding)\n",
    "        # self.embedding.weight.requires_grad = False if fix_embedding else True\n",
    "        \n",
    "        self.net = torch.nn.LSTM(embedding.size(1), hidden_dim, num_layers=num_layers, \\\n",
    "                                  bidirectional=bidirectional, batch_first=True)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        inputs = self.embedding[inputs]\n",
    "        x, _ = self.net(inputs)\n",
    "        return x\n",
    "    \n",
    "class Header(torch.nn.Module):\n",
    "    def __init__(self, dropout, hidden_dim):\n",
    "        super(Header, self).__init__()\n",
    "        # TODO: you should design your classifier module\n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Linear(hidden_dim, 1),\n",
    "                            torch.nn.Sigmoid())\n",
    "        \n",
    "    @ torch.no_grad()\n",
    "    def _get_length_masks(self, lengths):\n",
    "        # lengths: (batch_size, ) in cuda\n",
    "        ascending = torch.arange(MAX_POSITIONS_LEN)[:lengths.max().item()].unsqueeze(\n",
    "            0).expand(len(lengths), -1).to(lengths.device)\n",
    "        length_masks = (ascending < lengths.unsqueeze(-1)).unsqueeze(-1)\n",
    "        return length_masks\n",
    "    \n",
    "    def forward(self, inputs, lengths):\n",
    "        # the input shape should be (N, L, D∗H)\n",
    "        pad_mask = self._get_length_masks(lengths)\n",
    "        inputs = inputs * pad_mask\n",
    "        inputs = inputs.sum(dim=1)\n",
    "        out = self.classifier(inputs).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go3chn37CGs8"
   },
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WdfQS_0FWbG3"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, backbone, header, optimizer, criterion, device, epoch):\n",
    "\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "    \n",
    "    for i, (idx_list, lengths, texts, labels) in enumerate(train_loader):\n",
    "        lengths, inputs, labels = lengths.to(device), texts.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        if not backbone is None:\n",
    "            inputs = backbone(inputs)\n",
    "        soft_predicted = header(inputs, lengths)\n",
    "        loss = criterion(soft_predicted, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            hard_predicted = (soft_predicted >= 0.5).int()\n",
    "            correct = sum(hard_predicted == labels).item()\n",
    "            batch_size = len(labels)\n",
    "        \n",
    "            print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f}'.format(epoch+1, np.mean(total_loss), np.mean(total_acc)), end='\\r')\n",
    "    backbone.train()\n",
    "    header.train()\n",
    "    return np.mean(total_loss), np.mean(total_acc)\n",
    "\n",
    "def valid(valid_loader, backbone, header, criterion, device, epoch):\n",
    "    backbone.eval()\n",
    "    header.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = []\n",
    "        total_acc = []\n",
    "        \n",
    "        for i, (idx_list, lengths, texts, labels) in enumerate(valid_loader):\n",
    "            lengths, inputs, labels = lengths.to(device), texts.to(device), labels.to(device)\n",
    "\n",
    "            if not backbone is None:\n",
    "                inputs = backbone(inputs)\n",
    "            soft_predicted = header(inputs, lengths)\n",
    "            loss = criterion(soft_predicted, labels)\n",
    "            total_loss.append(loss.item())\n",
    "            \n",
    "            hard_predicted = (soft_predicted >= 0.5).int()\n",
    "            correct = sum(hard_predicted == labels).item()\n",
    "            acc = correct * 100 / len(labels)\n",
    "            total_acc.append(acc)\n",
    "            \n",
    "            print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f}'.format(epoch+1, np.mean(total_loss), np.mean(total_acc)), end='\\r')\n",
    "    backbone.train()\n",
    "    header.train()\n",
    "    return np.mean(total_loss), np.mean(total_acc)\n",
    "\n",
    "            \n",
    "def run_training(train_loader, valid_loader, backbone, header, epoch_num, lr, device, model_dir): \n",
    "    def check_point(backbone, header, loss, acc, model_dir, lossbest):\n",
    "        if loss <= lossbest:\n",
    "        # TODO\n",
    "          torch.save({'backbone': backbone, 'header': header}, model_dir)\n",
    "    def is_stop(loss, acc):\n",
    "        # TODO\n",
    "        if (epoch - bestepoch)>5:\n",
    "          return True\n",
    "        else:\n",
    "          return False\n",
    "    \n",
    "    if backbone is None:\n",
    "        trainable_paras = header.parameters()\n",
    "    else:\n",
    "        trainable_paras = list(backbone.parameters()) + list(header.parameters())\n",
    "        \n",
    "    optimizer = torch.optim.SGD(trainable_paras, lr=lr)\n",
    "    \n",
    "    backbone.train()\n",
    "    header.train()\n",
    "    backbone = backbone.to(device)\n",
    "    header = header.to(device)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    lossbest = 99999999\n",
    "    for epoch in range(epoch_num):\n",
    "        train(train_loader, backbone, header, optimizer, criterion, device, epoch)\n",
    "        loss, acc = valid(valid_loader, backbone, header, criterion, device, epoch)\n",
    "        print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f} '.format(epoch+1, loss, acc))\n",
    "        if loss<lossbest:\n",
    "          lossbest = loss\n",
    "          bestepoch = epoch\n",
    "        check_point(backbone, header, loss, acc, model_dir, lossbest)\n",
    "        if is_stop(loss, acc, bestepoch, epoch):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "5Evw4Q5O2dRJ",
    "outputId": "c953748e-13b5-44d9-feac-f737d15f31a5"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9827f71946db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m5\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'list'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbhQ7pueCJEt"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Amq9XWbEWbG9"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = preprocessor.embedding_matrix.to(device)\n",
    "\n",
    "backbone = Backbone(embedding_matrix, **net_config)\n",
    "header = Header(**header_config)\n",
    "\n",
    "run_training(train_loader, valid_loader, backbone, header, EPOCH_NUM, lr, device, MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Fg6zCjgCK5K"
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfKCUNWRWbHi"
   },
   "outputs": [],
   "source": [
    "def run_testing(test_loader, backbone, header, device, output_path):\n",
    "  with open(output_path, 'w') as f:\n",
    "    backbone.eval()\n",
    "    header.eval()\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'label'])\n",
    "    with torch.no_grad():\n",
    "      for i, (idx_list, lengths, texts) in enumerate(test_loader):\n",
    "        lengths, inputs = lengths.to(device), texts.to(device)\n",
    "        if not backbone is None:\n",
    "          inputs = backbone(inputs)\n",
    "        soft_predicted = header(inputs, lengths)\n",
    "        hard_predicted = (soft_predicted >= 0.5).int()\n",
    "        for i, p in zip(idx_list, hard_predicted):\n",
    "          writer.writerow([str(i.item()), str(p.item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "splMWxJn3_si"
   },
   "outputs": [],
   "source": [
    "def psuedo_label(unlabel_loader, backbone, header, device, output_path):\n",
    "  with open(output_path, 'w') as f:\n",
    "    backbone.eval()\n",
    "    header.eval()\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id', 'label'])\n",
    "    with torch.no_grad():\n",
    "      for i, (idx_list, lengths, texts) in enumerate(unlabel_loader):\n",
    "        lengths, inputs = lengths.to(device), texts.to(device)\n",
    "        if not backbone is None:\n",
    "          inputs = backbone(inputs)\n",
    "        soft_predicted = header(inputs, lengths)\n",
    "        hard_predicted = (soft_predicted >= 0.5).int()\n",
    "        for i, p in zip(idx_list, hard_predicted):\n",
    "          writer.writerow([str(i.item()), str(p.item())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wc9KxxSMCM8L"
   },
   "source": [
    "Make a submission file\n",
    "\n",
    "(Note: In principle, you don't need to modify this part, and please make sure that you follow the correct format of the produced files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_09sRVgeWbIk"
   },
   "outputs": [],
   "source": [
    "EXP_name = \"SampleCode\"\n",
    "pred_file = f'{EXP_name}-pred.csv'\n",
    "run_testing(test_loader, backbone, header, device, pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Z2pztd-H9N8"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(pred_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT2wmdsVDcX6"
   },
   "source": [
    "# Good luck for your programming assignments! \n",
    "If you have any questions, feel free to send e-mails to ntueemlta2022@gmail.com / b08202033@ntu.edu.tw. Of course, welcome to make use of the TA hours as well. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
